{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNwDmtm6NDbT8GlF2deBbuW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aiaaee/California_Housing/blob/main/CaliforniaHousing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "D2sE0Uiiyljx"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as f\n",
        "from torch.utils.data import Dataset , DataLoader\n",
        "import torch.optim as optim\n",
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from torchvision import transforms\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "lYpZoY-q1iKe"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = fetch_california_housing()\n",
        "# In dataset as_frame is false . it means that we need to create Dataset and do data and target combination\n",
        "X, y = data.data, data.target\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Standardize the features\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n"
      ],
      "metadata": {
        "id": "D2tFM3Xi--mo"
      },
      "execution_count": 215,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train.shape , y_train.shape)\n",
        "print(X_test.shape , y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ljmQMXKwDGZY",
        "outputId": "c5f948e7-55b9-443a-d3ca-aa840057d352"
      },
      "execution_count": 216,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(16512, 8) (16512,)\n",
            "(4128, 8) (4128,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lruTIt2bG_uv",
        "outputId": "5a734c5d-0997-4ac3-c489-585c65f0ea43"
      },
      "execution_count": 217,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.326196  ,  0.34849025, -0.17491646, ...,  0.05137609,\n",
              "        -1.3728112 ,  1.27258656],\n",
              "       [-0.03584338,  1.61811813, -0.40283542, ..., -0.11736222,\n",
              "        -0.87669601,  0.70916212],\n",
              "       [ 0.14470145, -1.95271028,  0.08821601, ..., -0.03227969,\n",
              "        -0.46014647, -0.44760309],\n",
              "       ...,\n",
              "       [-0.49697313,  0.58654547, -0.60675918, ...,  0.02030568,\n",
              "        -0.75500738,  0.59946887],\n",
              "       [ 0.96545045, -1.07984112,  0.40217517, ...,  0.00707608,\n",
              "         0.90651045, -1.18553953],\n",
              "       [-0.68544764,  1.85617335, -0.85144571, ..., -0.08535429,\n",
              "         0.99543676, -1.41489815]])"
            ]
          },
          "metadata": {},
          "execution_count": 217
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a custom PyTorch dataset\n",
        "\n",
        "toTensorTransform = transforms.Lambda(lambda x: torch.tensor(x, dtype=torch.float32))\n",
        "class CaliforniaHousingDataset(Dataset):\n",
        "    def __init__(self, features, targets, transform=None, target_transform=None):\n",
        "        self.features = features\n",
        "        self.targets = targets\n",
        "        self.transform = transform\n",
        "        self.target_transform = target_transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.features)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        x = self.features[index]\n",
        "        y = self.targets[index]\n",
        "        if self.transform:\n",
        "            x = self.transform(x)\n",
        "        if self.target_transform:\n",
        "            y = self.target_transform(y)\n",
        "        return x, y"
      ],
      "metadata": {
        "id": "XUYhnB5YDOSd"
      },
      "execution_count": 218,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create instances of the custom dataset\n",
        "train_dataset = CaliforniaHousingDataset(X_train, y_train, transform=toTensorTransform,\n",
        "                                         target_transform=transforms.Lambda(lambda x: torch.tensor(x, dtype=torch.float32).unsqueeze(0)))\n",
        "\n",
        "test_dataset = CaliforniaHousingDataset(X_test, y_test, transform=toTensorTransform,\n",
        "                                        target_transform=transforms.Lambda(lambda x: torch.tensor(x, dtype=torch.float32).unsqueeze(0)))\n",
        "\n",
        "# Create PyTorch data loaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n"
      ],
      "metadata": {
        "id": "1qoNQVtEDtZa"
      },
      "execution_count": 219,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for data, target in train_loader:\n",
        "    print(target.size())\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l0TliIY9Fvp9",
        "outputId": "ebd56a47-1af0-4462-cbea-c622464626f0"
      },
      "execution_count": 220,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([64, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class NeuralNet(nn.Module) :\n",
        "  def __init__(self , in_features , out_features , *args , **kwargs ):\n",
        "    super().__init__(*args , **kwargs)\n",
        "    self.flatten = nn.Flatten()\n",
        "    self.fc1 = nn.Linear(in_features , 200)\n",
        "    self.fc2 = nn.Linear(200 , 200)\n",
        "    self.fc3 = nn.Linear(200 , out_features)\n",
        "  def forward(self , x ):\n",
        "    x = self.flatten(x)\n",
        "    output = self.fc1(x)\n",
        "    output = nn.ReLU()(output)\n",
        "    output = self.fc2(x)\n",
        "    output = nn.ReLU()(output)\n",
        "    return self.fc3(output)\n"
      ],
      "metadata": {
        "id": "cPZY_RX7N2Ui"
      },
      "execution_count": 330,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = NeuralNet(8 , 1 )\n",
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "01bcM0TBPhrB",
        "outputId": "9e70d20f-61ab-429a-bc16-0f72cc20b4c1"
      },
      "execution_count": 331,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "NeuralNet(\n",
              "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
              "  (fc1): Linear(in_features=8, out_features=200, bias=True)\n",
              "  (fc2): Linear(in_features=200, out_features=200, bias=True)\n",
              "  (fc3): Linear(in_features=200, out_features=1, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 331
        }
      ]
    }
  ]
}